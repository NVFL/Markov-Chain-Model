{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(\n",
    "    n_samples = 2000, \n",
    "    n_features = 2, # number of x columns\n",
    "    n_redundant = 0, \n",
    "    n_clusters_per_class = 2, \n",
    "    flip_y = 0.6, # add noise\n",
    "    weights = [0.8], # set dataset imbalance\n",
    "    class_sep = 1.1, # set class separation\n",
    "    random_state = 1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(X), pd.Series(Y)], axis=1) #concatenate to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['x1','x2','y'] # rename columns\n",
    "#print(df) # unhashtag to check dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df: pd.DataFrame, x1: str, x2: str, y: str, title: str = '', save: bool = False, figname='figure.png'):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.scatter(x=df[df[y] == 0][x1], y=df[df[y] == 0][x2], label='y = 0')\n",
    "    plt.scatter(x=df[df[y] == 1][x1], y=df[df[y] == 1][x2], label='y = 1')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(figname, dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df=df, x1='x1', x2='x2', y='y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccba3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['y'],axis=1)\n",
    "Y = df.y\n",
    "clf1 = RandomForestClassifier(max_depth=2, random_state=1) # RF\n",
    "clf2 = GradientBoostingClassifier(max_depth=2, random_state=1) # XGBoost\n",
    "ypred1 = cross_val_predict(clf1, X, Y, cv=10)\n",
    "ypred2 = cross_val_predict(clf2, X, Y, cv=10)\n",
    "#print(classification_report(Y, ypred1)) # unhashtag to print RF classification report for dataframe\n",
    "#print(classification_report(Y, ypred2)) # unhashtag to print XGBoost classification report for dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bespoke Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataframe into 25 equal chunks\n",
    "def split_dataframe_by_position(df, splits): \n",
    "    dataframes = []\n",
    "    index_to_split = len(df) // splits\n",
    "    start = 0\n",
    "    end = index_to_split\n",
    "    for split in range(splits):\n",
    "        temp_df = df.iloc[start:end, :]\n",
    "        dataframes.append(temp_df)\n",
    "        start += index_to_split\n",
    "        end += index_to_split\n",
    "    return dataframes\n",
    "split_dataframes = split_dataframe_by_position(df, 25)\n",
    "#print(split_dataframes) # unhashtag to check split dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccba3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in split_dataframes:\n",
    "    #df = list_df[]\n",
    "    X = df.drop(['y'],axis=1)\n",
    "    Y = df.y\n",
    "    clf1 = RandomForestClassifier(max_depth=2, random_state=1) # RF\n",
    "    clf2 = GradientBoostingClassifier(max_depth=2, random_state=1) # XGBoost\n",
    "    ypred1 = cross_val_predict(clf1, X, Y, cv=10)\n",
    "    ypred2 = cross_val_predict(clf2, X, Y, cv=10)\n",
    "    #print(classification_report(Y, ypred1)) # unhashtag to print RF classification report for each split dataframe\n",
    "    #print(classification_report(Y, ypred2)) # unhashtag to print XGBoost classification report for each split dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b83ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate and concatenate PFIs for RF model of each split dataframe \n",
    "coef1 = []\n",
    "for df in split_dataframes:\n",
    "    X = df.drop(['y'],axis=1)\n",
    "    Y = df.y\n",
    "    clf1 = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "    clf1.fit(X, Y)\n",
    "    result1 = permutation_importance(clf1, X, Y, n_repeats=10, random_state=1, n_jobs=2)\n",
    "    feature_importances1 = pd.Series(result1.importances_mean, index=X.columns)\n",
    "    coef1.append(feature_importances1)\n",
    "coef1 = pd.concat(coef1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b83ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate and concatenate PFIs for XGBoost model of each split dataframe \n",
    "coef2 = []\n",
    "for df in split_dataframes:\n",
    "    X = df.drop(['y'],axis=1)\n",
    "    Y = df.y\n",
    "    clf2 = GradientBoostingClassifier(max_depth=2, random_state=1)\n",
    "    clf2.fit(X, Y)\n",
    "    result2 = permutation_importance(clf2, X, Y, n_repeats=10, random_state=1, n_jobs=2)\n",
    "    feature_importances2 = pd.Series(result2.importances_mean, index=X.columns)\n",
    "    coef2.append(feature_importances2)\n",
    "coef2 = pd.concat(coef2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd64b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate PFIs for all RF and XGBoost models\n",
    "coef = pd.concat([coef1, coef2])\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fc6bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot clustermap using pairwise correlation as metric and ward as method\n",
    "sns.clustermap(coef.corr(),yticklabels=True,xticklabels=True,method='ward', figsize=(7,7), cmap=\"coolwarm\")\n",
    "sns.set(font_scale=1.2)#dates removed 22h"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "590a275a3f98fd7e913537108912216682cc03e398db0fbf7a4a5ad816620ded"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('sandbox': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
