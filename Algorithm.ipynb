{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID transition data\n",
    "df = pd.read_csv('COVID_kitchen_.csv').iloc[:,1:]\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-COVID transition data \n",
    "df = pd.read_csv('kitchen_.csv').iloc[:,1:]\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchen_ = df.groupby('household').resample('1h',on='start_date').agg(vc = ('transition','value_counts')).fillna(0).reset_index().rename(columns = {'vc': 'transition_count'}) # where df is COVID_kitchen_ or kitchen_\n",
    "kitchen_['date'] = kitchen_['start_date'].dt.date\n",
    "kitchen_['hour'] = kitchen_['start_date'].dt.hour \n",
    "kitchen_ = kitchen_.pivot(index=['household','transition','date'], columns='hour', values='transition_count').fillna(0)\n",
    "kitchen_ = kitchen_.reset_index()\n",
    "kitchen_ = kitchen_.melt(id_vars=['household','transition','date'], var_name='hour', value_name='transition_count')\n",
    "kitchen_ = kitchen_.pivot(index=['household','date','hour'], columns='transition', values='transition_count').fillna(0)\n",
    "kitchen_ = kitchen_.reset_index()\n",
    "kitchen_ = kitchen_.melt(id_vars=['household','date','hour'], var_name='transition', value_name='transition_count')\n",
    "kitchen_ = kitchen_.pivot(index=['household','transition','hour'], columns='date', values='transition_count')\n",
    "kitchen_ = kitchen_.where(kitchen_.notna(), kitchen_.median(axis=1), axis=0)\n",
    "kitchen_ = kitchen_.reset_index()\n",
    "kitchen_ = kitchen_.melt(id_vars=['household','transition','hour'], var_name='date', value_name='transition_count')\n",
    "kitchen_.columns = ['household','transition','hour','start_date','transition_count']\n",
    "kitchen_['start_date'] = pd.to_datetime(kitchen_['start_date'])\n",
    "kitchen_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract transition probabilities\n",
    "def get_markov_prob(df:pd.DataFrame,start:str,end:str): \n",
    "    dummy = df.query(\"@start < start_date < @end\")\n",
    "    dummy = dummy.groupby(['household','hour','transition'])['transition_count'].sum().to_frame().unstack().fillna(0).stack().reset_index()\n",
    "    dummy['transition'] = dummy.transition.astype(str)\n",
    "    dummy[['source','sink']] = dummy.transition.str.split('>', expand=True)\n",
    "    dummy['total'] = dummy.groupby(['household','hour','source'])['transition_count'].transform('sum')\n",
    "    dummy['markov'] = dummy['transition_count']/dummy['total']\n",
    "    dummy['markov'] = dummy.markov.fillna(0)\n",
    "    dummy = dummy.set_index(['household','hour','source','sink'])['markov'].unstack().fillna(0)\n",
    "    return(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up for the sliding window\n",
    "df = kitchen_\n",
    "bwin,cwin,freq = (3,'W'),(1,'W'),'1d'\n",
    "start_date,end_date = df.start_date.dt.date.agg(['min','max']).astype('datetime64[ns]')\n",
    "base_line = start_date + np.timedelta64(*bwin)\n",
    "current = base_line + np.timedelta64(*cwin)\n",
    "clean_date = lambda x: pd.to_datetime(str(x.date())) #clearing time out because timedelta brings in time\n",
    "rng = pd.date_range(clean_date(base_line),clean_date(end_date),freq=freq)\n",
    "#sliding window\n",
    "similarity = {}\n",
    "for win in rng:\n",
    "    baseline_markov = get_markov_prob(df,base_line-np.timedelta64(*bwin),base_line)\n",
    "    current_markov = get_markov_prob(df,current-np.timedelta64(*cwin),current)\n",
    "    similarity[win] = (baseline_markov-current_markov).groupby(['household','hour']).apply(lambda x: np.linalg.norm(x.values))\n",
    "    shift = win - base_line\n",
    "    base_line,current = base_line + shift,current + shift\n",
    "    #print(f'{base_line}-{current}')\n",
    "    #print(baseline_markov)\n",
    "    #print(current_markov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity = pd.DataFrame.from_dict(similarity) # return as dataframe\n",
    "df_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "730e964555fb2542a911b5002c3c4a5ea6b8ea7e74d00811d465953d33b870ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
